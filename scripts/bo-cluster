#!/usr/bin/env python
# -*- coding: utf8 -*-

"""
Copyright (C) 2014 Andreas Würl

This program is free software: you can redistribute it and/or modify it under the terms of the GNU Affero General Public License as published by the Free Software Foundation, version 3.

This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Affero General Public License for more details.

You should have received a copy of the GNU Affero General Public License along with this program. If not, see <http://www.gnu.org/licenses/>.

"""

from __future__ import print_function

import json

import os
import logging
import time
import datetime
import pytz

from optparse import OptionParser
from lockfile.pidlockfile import PIDLockFile
from shapely.geometry import mapping

from blitzortung import root_logger
import blitzortung.db
import blitzortung.clustering
import blitzortung.builder
import blitzortung.logger

logger = logging.getLogger(os.path.basename(__file__))
logger.parent = root_logger
root_logger.addHandler(blitzortung.logger.create_console_handler())


def detect_clusters(strikes_db, start_time, duration):
    end_time = start_time + duration
    time_interval = blitzortung.db.query.TimeInterval(start_time, end_time)
    strikes = strikes_db.select(time_interval)

    clustering = blitzortung.clustering.Clustering(blitzortung.builder.StrikeCluster())

    return clustering.build_clusters(strikes, time_interval)


def import_clusters(options):
    lock = PIDLockFile('/tmp/.bo-cluster.pid', timeout=10)

    with lock:
        if options.debug:
            root_logger.setLevel(logging.DEBUG)
        elif options.verbose:
            root_logger.setLevel(logging.INFO)

        strikes_db = blitzortung.db.strike()
        latest_strike_time = strikes_db.get_latest_time()
        cluster_db = blitzortung.db.strike_cluster()
        latest_cluster_time = cluster_db.get_latest_time()

        if latest_cluster_time is None:
            if options.start_date is None:
                now = datetime.datetime.utcnow()
                now = now.replace(tzinfo=pytz.UTC)

                latest_cluster_time = now.replace(second=0, microsecond=0) - datetime.timedelta(minutes=240)
            else:
                latest_cluster_time = datetime.datetime.strptime(options.start_date, "%Y%m%d").replace(tzinfo=pytz.UTC)

            logger.info("start @ {}".format(latest_cluster_time))

        duration = datetime.timedelta(minutes=10)
        time_step = datetime.timedelta(minutes=1)

        cluster_group_size = 5000
        cluster_group_strike_count = 0
        global_start_time = start_time = time.time()
        cluster_count = 0
        strike_count = 0
        while True:
            if latest_cluster_time is not None:
                if latest_cluster_time + time_step > latest_strike_time:
                    break

            latest_cluster_time += time_step

            for cluster in detect_clusters(strikes_db, latest_cluster_time - duration, duration):
                cluster_db.insert(cluster)

                cluster_count += 1
                strike_count += cluster.get_strike_count()
                cluster_group_strike_count += cluster.get_strike_count()
                if cluster_count % cluster_group_size == 0:
                    cluster_db.commit()
                    group_timedelta = (time.time() - start_time)
                    logger.info("commit #{} ({:.1f} clusters/s, {:.1f} strikes/s) @{}".format(
                        cluster_count, cluster_group_size / group_timedelta, cluster_group_strike_count / group_timedelta, cluster.get_timestamp()))
                    start_time = time.time()
                    cluster_group_strike_count = 0

        cluster_db.commit()
	
	time_delta = time.time() - global_start_time
        logger.info("#{} clusters detected ({:.1f} cluster/s, {:.1f} strikes/s)".format(
            cluster_count, cluster_count / time_delta, strike_count / time_delta))


def dump_clusters(options):
    cluster_db = blitzortung.db.strike_cluster()

    latest_time = cluster_db.get_latest_time()
    if latest_time is None:
       print("no clusters found")
       return

    interval_duration = datetime.timedelta(minutes=10)
    clusters = cluster_db.select(latest_time, interval_duration, 1, datetime.timedelta(seconds=0))

    cluster_data = tuple(
        (mapping(cluster.get_shape())['coordinates'], cluster.get_strike_count()) for cluster in clusters)

    reference_time = latest_time
    interval_seconds = int(interval_duration.total_seconds())
    if options.json_output:
        output = {
                'timestamp': reference_time.strftime('%Y%m%d %H%M%S'),
                'interval_seconds': interval_seconds,
                'clusters': cluster_data}

        print(json.dumps(output))
    else:
        print("{} clusters {} seconds before {}".format(len(cluster_data), interval_seconds, str(reference_time)))
        for cluster in cluster_data:
            print("{:6d} strikes in {}".format(cluster[1], ", ".join([" ".join([str(coordinate) for coordinate in coordinate_pair]) for coordinate_pair in cluster[0]])))


if __name__ == "__main__":
    parser = OptionParser()
    parser.add_option("-m", "--mode", dest="mode", default="dump", help="mode: 'dump', 'import'")
    parser.add_option("-j", "--json-output", dest="json_output", action="store_true", help="switch to JSON output format")
    parser.add_option("-v", "--verbose", dest="verbose", action="store_true", help="verbose output")
    parser.add_option("-d", "--debug", dest="debug", action="store_true", help="debug output")
    parser.add_option("--startdate", dest="start_date", default=None, help="import start date")

    (options, args) = parser.parse_args()

    if options.mode == 'dump':
        dump_clusters(options)
    elif options.mode == 'import':
        import_clusters(options)

